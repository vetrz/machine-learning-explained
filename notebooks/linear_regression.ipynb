{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124d3e31",
   "metadata": {},
   "source": [
    "## Modelo de Regressão Linear\n",
    "\n",
    "Esse modelo é dividido em partes, são elas:\n",
    "\n",
    "### 1. Hipótese (Modelo)\n",
    "\n",
    "A hipótese $h_\\theta(x)$ representa a função que o modelo está tentando aprender para mapear as entradas ($x$) para as saídas ($y$). Na Regressão Linear com múltiplas variáveis (ou uma única variável), ela é um modelo linear:\n",
    "\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n = \\sum_{i=0}^{n} \\theta_i x_i$$\n",
    "\n",
    "Em notação vetorial, onde $\\mathbf{\\theta}$ é o vetor de parâmetros e $\\mathbf{x}$ é o vetor de características (assumindo que $x_0=1$ para o termo de interceptação $\\theta_0$):\n",
    "\n",
    "$$h_\\theta(\\mathbf{x}) = \\mathbf{\\theta}^T \\mathbf{x}$$\n",
    "\n",
    "### 2. Função de Custo (Compute Cost)\n",
    "\n",
    "A função de custo $J(\\theta)$ mede a precisão da hipótese comparando as previsões $h_\\theta(x^{(i)})$ com os valores reais $y^{(i)}$ nos $m$ exemplos de treinamento. O objetivo é minimizar esta função. A forma mais comum é o **Erro Quadrático Médio (Mean Squared Error - MSE)**:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "### 3. Gradiente Descendente (Gradient Descent)\n",
    "\n",
    "O Gradiente Descendente é um algoritmo iterativo para encontrar os valores dos parâmetros $\\theta$ que minimizam a função de custo $J(\\theta)$. Ele atualiza cada parâmetro $\\theta_j$ simultaneamente em cada passo:\n",
    "\n",
    "**Repita até convergir:**\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta)$$\n",
    "\n",
    "Onde $\\alpha$ é a taxa de aprendizado (learning rate).\n",
    "\n",
    "Para a Regressão Linear, a derivada parcial é:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_j} J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}$$\n",
    "\n",
    "Portanto, a regra de atualização para cada parâmetro $\\theta_j$ é:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}$$\n",
    "\n",
    "### 4. Método de Newton (para minimização)\n",
    "\n",
    "O Método de Newton é uma alternativa ao Gradiente Descendente, geralmente mais rápido para convergir, especialmente com um grande número de características, mas com um custo computacional maior por iteração devido à necessidade de calcular e inverter a matriz Hessiana.\n",
    "\n",
    "A regra de atualização vetorial para o Método de Newton é:\n",
    "\n",
    "$$\\theta := \\theta - H^{-1} \\nabla_\\theta J(\\theta)$$\n",
    "\n",
    "Onde:\n",
    "* $\\nabla_\\theta J(\\theta)$ é o **vetor gradiente** da função de custo $J(\\theta)$, contendo todas as derivadas parciais:\n",
    "    $$\\nabla_\\theta J(\\theta) = \\begin{bmatrix} \\frac{\\partial J}{\\partial \\theta_0} \\\\ \\frac{\\partial J}{\\partial \\theta_1} \\\\ \\vdots \\\\ \\frac{\\partial J}{\\partial \\theta_n} \\end{bmatrix}$$\n",
    "* $H$ é a **matriz Hessiana**, uma matriz $(n+1) \\times (n+1)$ de segundas derivadas parciais:\n",
    "    $$H_{jk} = \\frac{\\partial^2 J(\\theta)}{\\partial \\theta_j \\partial \\theta_k}$$\n",
    "\n",
    "\n",
    "## Padronização (Z-Score)\n",
    "\n",
    "A Padronização, utilizando o Z-Score, é uma técnica de pré-processamento de dados que transforma as características para que elas tenham uma **média de zero** e um **desvio-padrão de um**.\n",
    "\n",
    "### 1. Fórmula do Z-Score (Padronização)\n",
    "\n",
    "Para cada ponto de dados $x_j$ (o valor da característica $j$), a transformação é feita subtraindo a média da característica ($\\mu_j$) e dividindo pelo desvio-padrão ($\\sigma_j$).\n",
    "\n",
    "$$x'_j = \\frac{x_j - \\mu_j}{\\sigma_j}$$\n",
    "\n",
    "Onde:\n",
    "* $x'_j$: O novo valor padronizado (Z-Score).\n",
    "* $\\mu_j$: Média dos valores da característica $j$ no conjunto de treinamento.\n",
    "* $\\sigma_j$: Desvio-padrão dos valores da característica $j$ no conjunto de treinamento.\n",
    "\n",
    "### 2. Por Que Padronizar na Regressão Linear\n",
    "\n",
    "A padronização é especialmente crucial quando o modelo de Regressão Linear é treinado utilizando o algoritmo de **Gradiente Descendente**.\n",
    "\n",
    "| Aspecto | Explicação Breve |\n",
    "| :--- | :--- |\n",
    "| **Velocidade de Convergência** | Sem padronização, a função de custo $J(\\theta)$ fica alongada e o Gradiente Descendente tem dificuldade em convergir rapidamente, podendo oscilar. A padronização centraliza a função de custo , permitindo uma convergência **muito mais rápida**. |\n",
    "| **Importância Equilibrada** | A padronização garante que variáveis com escalas muito diferentes (e.g., \"área da casa\" em metros quadrados e \"número de quartos\") sejam tratadas de forma **equitativa**. Caso contrário, a variável com maior magnitude numérica pode dominar a função de custo. |\n",
    "\n",
    "* **Observação:** Se o modelo for resolvido usando a **Equação Normal** (solução de forma fechada, não iterativa), a padronização não é estritamente necessária para obter a solução correta dos parâmetros $\\theta$, mas ainda é útil para a interpretabilidade dos coeficientes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bed7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(noise=20, random_state=42, n_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(X, theta) -> np.ndarray:\n",
    "    return np.dot(X, theta)  # product of matrices\n",
    "\n",
    "\n",
    "def compute_cost(X, y, theta) -> float:\n",
    "    m = len(y)\n",
    "    predictions = hypothesis(X, theta)\n",
    "    sq_errors = (predictions - y) ** 2\n",
    "    J = 1 / 2 * (1 / m) * np.sum(sq_errors)  # compute cost j(theta)\n",
    "    return J\n",
    "\n",
    "\n",
    "def gradient_descent(X, y, theta, alpha, num_iters) -> tuple:\n",
    "    m = len(y)\n",
    "    j_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        predictions = hypothesis(X, theta)\n",
    "        errors = predictions - y\n",
    "        theta = theta - (alpha / m) * (X.T.dot(errors))\n",
    "        j_history.append(compute_cost(X, y, theta))\n",
    "\n",
    "    return theta, j_history  # return final parameters and cost history\n",
    "\n",
    "\n",
    "def newton_method(X, y, theta, num_iters) -> tuple:\n",
    "    m = len(y)\n",
    "    j_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        predictions = hypothesis(X, theta)\n",
    "        errors = predictions - y\n",
    "        gradient = (1 / m) * (X.T.dot(errors))\n",
    "        hessian = (1 / m) * (X.T.dot(X))\n",
    "        theta = theta - np.linalg.inv(hessian).dot(gradient)\n",
    "        j_history.append(compute_cost(X, y, theta))\n",
    "\n",
    "    return theta, j_history\n",
    "\n",
    "\n",
    "def padronize_column(column) -> np.ndarray:\n",
    "    mean = np.mean(column)\n",
    "    std = np.std(column)\n",
    "    return (column - mean) / std  # padronizing data of column\n",
    "\n",
    "\n",
    "# Preparing data\n",
    "\n",
    "X = X.reshape(-1, 1)  # feature matrix, reshaped to be a 2D array\n",
    "y = y.reshape(-1, 1)  # target vector, reshaped to be a 2D array\n",
    "\n",
    "m = len(y)  # number of training examples\n",
    "X_b = np.c_[np.ones((m, 1)), X]  # add bias term\n",
    "X_b[:, 1] = padronize_column(X_b[:, 1])  # padronizing feature column\n",
    "y = padronize_column(y)  # padronizing target column\n",
    "theta_initial = np.zeros((2, 1))  # initial theta parameters randomly set to zero\n",
    "alpha = 0.01  # learning rate\n",
    "num_iters = 600  # number of iterations for gradient descent\n",
    "\n",
    "\n",
    "theta_final_gradient, j_history_gradient = gradient_descent(\n",
    "    X_b, y, theta_initial, alpha, num_iters\n",
    ")  # run gradient descent\n",
    "\n",
    "theta_final_newton, j_history_newton = newton_method(\n",
    "    X_b, y, theta_initial, num_iters\n",
    ")  # run newton method\n",
    "\n",
    "print(f\"\"\"Final theta parameters of gradient descent, theta 0 and theta 1 ,respectively: {theta_final_gradient.ravel()}\n",
    "Final theta parameters of newton method, theta 0 and theta 1 ,respectively: {theta_final_newton.ravel()}\"\"\")  # ravel to print as 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81350031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(j_history_gradient)), j_history_gradient)\n",
    "plt.plot(range(len(j_history_newton)), j_history_newton, ls=\"--\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Cost J\")\n",
    "plt.title(\"Convergence of Gradient Descent vs Newton Method\")\n",
    "plt.legend([\"Gradient Descent\", \"Newton Method\"])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_sklearn = LinearRegression()\n",
    "linear_sklearn.fit(X, y)\n",
    "\n",
    "print(\n",
    "    f\"Sklearn model coefficients: intercept/theta 0 = {linear_sklearn.intercept_[0]}, slope/theta 1 = {linear_sklearn.coef_[0][0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "\n",
    "models = [\n",
    "    LinearRegression().fit(X, y).predict(X),\n",
    "    hypothesis(X_b, theta_final_gradient),\n",
    "    hypothesis(X_b, theta_final_newton),\n",
    "]\n",
    "\n",
    "name_models = [\n",
    "    \"Sklearn Regression\",\n",
    "    \"Gradient Descent Regression\",\n",
    "    \"Newton Method Regression\",\n",
    "]\n",
    "colors = [\"green\", \"red\", \"orange\"]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    axs[i].scatter(X, y, color=\"black\", label=\"Data Points\")\n",
    "    axs[i].plot(X, model, color=f\"{colors[i]}\", label=f\"{name_models[i]} line\")\n",
    "    axs[i].set_xlabel(\"Tv advertisind Spend\")\n",
    "    axs[i].set_ylabel(\"Sales\")\n",
    "    axs[i].grid(True)\n",
    "    axs[i].legend()\n",
    "    if i == 0:\n",
    "        axs[i].set_title(\"Sklearn Regression\")\n",
    "    elif i == 1:\n",
    "        axs[i].set_title(\"Gradient Descent Regression\")\n",
    "    else:\n",
    "        axs[i].set_title(\"Newton Method Regression\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_gradient = mean_squared_error(y, hypothesis(X_b, theta_final_gradient))\n",
    "mse_sklearn = mean_squared_error(y, linear_sklearn.predict(X))\n",
    "mse_newton = mean_squared_error(y, hypothesis(X_b, theta_final_newton))\n",
    "\n",
    "print(f\"gradient: {mse_gradient}; sklearn: {mse_sklearn}; newton: {mse_newton}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linear-model-regression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
